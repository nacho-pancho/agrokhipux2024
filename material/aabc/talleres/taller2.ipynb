{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1bQRKBrXKfaYhxB_eu3BK1wzKvzqTjUAl","timestamp":1627221620835}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LohJysf-Gmw0"},"source":["# Taller 2 - Aprendizaje Supervisado\n","\n","La segunda clase del curso fue una introducción al que puede ser el tipo mas popular de Aprendizaje Automatico, el Aprendizaje Supervisado. Los distintos modelos que se agrupan bajo este termino son utilizados para variadas tareas y aplicados en areas muy diversas.\n","\n","En este taller vamos a explorar dos algoritmos simples, como lo son la regresión lineal y los arboles de decision. Estos dos modelos han sabido obtener muy buenos resultados en las tareas que cumplen (¡que son distintas!), y variaciones sobre los conceptos que introducen volveran a aparecer a lo largo del curso.\n","\n","El objetivo es que conozcan algunos de estos modelos a traves de trabajar con dos bases de datos nuevas y tambien bastante populares como lo son el Boston Housing dataset y el Penguins dataset. Exploraremos variaciones sobre los algoritmos y herramientas para interpretar los resultados.\n"]},{"cell_type":"markdown","metadata":{"id":"u5so2A-18pH9"},"source":["## Ejercicio 1 - Regresion Lineal\n","\n","Como vimos en el curso, la regresion lineal es una tecnica de **modelado predictivo** que encuentra relaciones entre variables independientes $x_i$, que pueden ser *categoricas* (e.g. \"Bueno\", \"Intermedio\", \"Malo\") o *continuas* (24, 3.14, etc), y predice una **respuesta $y$ continua**.\n","\n","Las tecnicas de regresion son ampliamente usadas para prediccion y modelado de series temporales, y un ejemplo es la prediccion de precios a partir de variables del mercado.\n","\n","### 1.1 - Boston Housing\n","\n","Este dataset incluye 13 caracteristicas (como habitaciones por hogar, ratio alumno/docente en las escuelas,y robos per capita, entr otros), para más de 500 barrios y suburbios de la ciudad de Boston, Massachusetts, EEUU."]},{"cell_type":"code","metadata":{"id":"O2b8gVz7y6X0"},"source":["# Como siempre, comenzamos importando los paquetes necesarios\n","!pip install scikit-learn==1.1.3\n","import numpy as np # paquete con funcionalidades matemáticas\n","import pandas as pandas # paquete que permite manipular datos con formato de tabla\n","from pandas import plotting as pandas_plot # funciones para graficar datos de tablas\n","import matplotlib.pyplot as plt # funciones generales para graficar\n","from sklearn.model_selection import train_test_split # separación de datos en entrenamiento y validación\n","from sklearn.linear_model import LinearRegression,Ridge,Lasso # modelos para calcular regresión lineal\n","from sklearn.metrics import mean_squared_error, r2_score # funciones para medir rendimiento de la regresión\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vafz-11c5eyj"},"source":["# y cargando el set de datos\n","from sklearn.datasets import load_boston\n","\n","boston_dataset = load_boston()\n","X, y = load_boston(return_X_y=True)\n","n,m = X.shape\n","# Imprimimos informacion sobre el dataset\n","print(f\"datos: {n} muestras de dimensión {m} cada una.\")\n","print(boston_dataset.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZYebPLL8VO4"},"source":["# Como con Iris, podemos imprimir informacion sobre el dataset,\n","# incluyendo cuales son las 13 caracteristicas\n","print('Descripción:\\n',boston_dataset['DESCR'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3Y8PWVm5wRg"},"source":["# Obtenemos los datos para entrenar, de la misma forma que en el Taller 1\n","#\n","caracteristicas = boston_dataset['feature_names']\n","muestras = boston_dataset['data']\n","etiquetas = boston_dataset['target']\n","\n","# Separamos el dataset en un conjunto de entrenamiento y otro de testeo\n","Xtrain, Xtest, ytrain, ytest = train_test_split(muestras, etiquetas)\n","#"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9x5fOga9PLm"},"source":["En la descripción de arriba se ve que aparecen 14 características (o atributos), porque está incluído el valor medio de las casas (**MEDV**), que es lo que queremos predecir.\n","\n","Otra forma de visualizar un set de datos con muchas variables es usando una matriz de correlación, donde cada cuadrado muestra la correlación entre dos variables. Abajo tiene el código para imprimir una matriz de correlación, para el Boston Housing dataset, incluyendo la variable que queremos predecir, el MEDV."]},{"cell_type":"code","metadata":{"id":"s2j65iOZ8w_1"},"source":["# llevamos el dataset a un dataframe de pandas\n","boston = pandas.DataFrame(Xtrain, columns=boston_dataset.feature_names)\n","# agregamos el valor medio de las casas (MEDV) que es nuestro target\n","boston['MEDV'] = ytrain\n","\n","# calculamos la matriz de correlacion con .corr()\n","# .round(2) redondea a dos cifras significativas\n","matriz_correlacion = boston.corr().round(2)\n","# annot = True imprime los valores adentro de las celdas\n","plt.figure(figsize=(10,10))\n","sns.heatmap(data=matriz_correlacion, annot=True, cmap=\"RdBu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tZ44Hs7pzqO"},"source":["Analizando la matriz de correlación, ¿qué características piensa pueden ser útiles para predecir MEDV? ¿Porqué? ¿Da lo mismo una correlación muy positiva que una muy negativa?\n","\n","**Extra 1.1** Experimenten con otras formas de visualizar el dataset, pueden ser histogramas, observar una parte de los datos con la funcion .head() de _pandas_, o cualquier otra que se les ocurra."]},{"cell_type":"markdown","metadata":{"id":"lJa9GxvAqtRa"},"source":["*Puede insertar su respuesta aquí:*\n","\n","Y de yapa, una propuesta de visualizacion de los datos:"]},{"cell_type":"code","metadata":{"id":"c8aGNXU7-zHh"},"source":["# Seleccione las variables que quiera usar para ajustar el modelo\n","# Recuerde que las variables posibles son:\n","# 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD','TAX', 'PTRATIO', 'B' y 'LSTAT'\n","#\n","variablesUsadas = ['INDUS', 'AGE', 'CRIM', 'NOX', 'RAD'] # MODIFICABLE\n","\n","# Extraemos los índices de las columnas que corresponden a esos nombres, usando list comprehensions\n","indicesUsados = [i for i, val in enumerate(caracteristicas) if val in variablesUsadas]\n","\n","# Con los índices, armamos Xtrain y Xtest incompletos, con sólo las columnas especificadas\n","Xtrain_inc = Xtrain[:,indicesUsados]\n","Xtest_inc = Xtest[:,indicesUsados]\n","#\n","# Y graficamos un scatter plot de las variables a utilizar\n","plt.figure(figsize=(20, 5))\n","for i, col in enumerate(indicesUsados):\n","    plt.subplot(1, len(indicesUsados) , i+1)\n","    x = Xtrain[:,col]\n","    y = ytrain\n","    plt.scatter(x, y, marker='o')\n","    plt.title(caracteristicas[col])\n","    plt.xlabel(caracteristicas[col])\n","    plt.ylabel('MEDV')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrVmSSRwqnhk"},"source":["Luego de haber observado un poco los datos con los que vamos a trabajar, procedemos a entrenar un modelo de la misma manera que en el notebook de práctico."]},{"cell_type":"code","metadata":{"id":"JvaXvvoXGk95"},"source":["# Entrenamos el modelo con las variables seleccionadas y medimos el rendimiento\n","#\n","# Primero definimos nuestro modelo de regresión lineal\n","lr_inc = LinearRegression()\n","#\n","# Luego lo ajustamos a los las columnas seleccionadas (note que usamos Xtrain_inc en lugar de Xtrain)\n","lr_inc.fit(Xtrain_inc, ytrain)\n","#\n","# Y finalmente, obtenemos las métricas de evaluación para el set de entrenamiento y de testeo y las imprimimos:\n","#\n","# evaluacion modelo sobre los datos de entrenamiento\n","ytrain_predict = lr_inc.predict(Xtrain_inc)\n","r2_train = r2_score(ytrain, ytrain_predict)\n","# evaluacion del modelo sobre los datos de testeo\n","ytest_predict = lr_inc.predict(Xtest_inc)\n","r2_test = r2_score(ytest, ytest_predict)\n","#\n","print( f\"R2 en training set es {r2_train:5.3f}, y en el test set es de {r2_test:6.3f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m4l2x1iGuDtQ"},"source":["El seleccionar qué variables son relevantes según nuestras expectativas, en lugar de usar todos los datos disponibles, puede ser una forma de prevenir el overfitting. Veamos que pasa si ajustamos la regresión lineal usando todas las variables, en lugar de las seleccionadas:"]},{"cell_type":"code","metadata":{"id":"x2KsREovJXbW"},"source":["# Ajustamos una regresión a todas las columnas\n","#\n","# Primero definimos nuestro modelo\n","lr = LinearRegression()\n","#\n","# Luego lo ajustamos a todos los datos\n","#\n","### RELLENE LO QUE FALTA en esta línea para entrenar al modelo con todas las variables\n","#\n","# Obtenemos las métricas de evaluación para el set de entrenamiento y de testeo y las imprimimos:\n","#\n","# evaluacion modelo sobre los datos de entrenamiento\n","ytrain_predict = lr.predict(Xtrain)\n","r2_train = r2_score(ytrain, ytrain_predict)\n","# evaluacion del modelo sobre los datos de testeo\n","ytest_predict = # RELLENE LO QUE FALTA\n","r2_test = # RELLENE LO QUE FALTA\n","#\n","print( f\"Usando todas las columnas, R2 en training set es {r2_train:5.3f}, y en el test set es de {r2_test:6.3f}\" )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a0dJab73u2-R"},"source":["¿Cómo cambia el rendimiento entre usar sólo las columnas seleccionadas o usarlas todas? ¿Qué concluye? ¿Piensa que este resultado podría cambiar si tuvieramos muchos menos datos?"]},{"cell_type":"markdown","metadata":{"id":"0g678vzqvHNV"},"source":["*Puede insertar su respuesta aquí:*"]},{"cell_type":"markdown","metadata":{"id":"jpp8cMgM7qWY"},"source":["Una forma más \"automática\" de elegir qué variables son relevantes para la regresión es mediante el uso de regularización. Intente mejorar el rendimiento del modelo aplicando una regresión de Ridge, y otra regreson de Lasso, **rellenando el código incompleto de abajo**"]},{"cell_type":"code","metadata":{"id":"4fKLhV7jyLfb"},"source":["# Primero defina el modelo de Ridge. Busque como hacerlo en el cuaderno del práctico 2-1,\n","# al final donde se muestra la regularización. Note que debe elegir el valor\n","# del parámetro de regularización.\n","#\n","modeloRidge = ### LLENAR: Defina el modelo Ridge\n","#\n","# Luego ajuste el modelo definido a los datos de todas las columnas\n","modeloRidge.fit() ### LLENAR: llene el paréntesis con lo necesario para entrenar el modelo\n","#\n","# Ahora haga lo mismo pero para un modelo tipo Lasso\n","### LLENAR: Defina el modelo Lasso\n","#\n","modeloLasso.fit() ### LLENAR: llene el paréntesis con lo necesario para entrenar el modelo\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RUQYIxt2u96"},"source":["#\n","# Luego evaluamos el rendimiento de los modelos\n","#\n","# Evaluación Ridge:\n","ytrain_predict_ridge = ### LLENAR: Llene para obtener las predicciones del modelo ridge para el set de ENTRENAMIENTO\n","r2_train_ridge = r2_score(ytrain, ytrain_predict_ridge)\n","# evaluacion del modelo sobre los datos de testeo\n","ytest_predict_ridge = ### LLENAR: Llene para obtener las predicciones del modelo ridge para el set de TESTEO\n","r2_test_ridge = r2_score(ytest, ytest_predict_ridge)\n","#\n","# Evaluación LASSO\n","ytrain_predict_lasso = ### LLENAR: Llene para obtener las predicciones del modelo lasso para el set de ENTRENAMIENTO\n","r2_train_lasso = r2_score(ytrain, ytrain_predict_lasso)\n","# evaluacion del modelo sobre los datos de testeo\n","ytest_predict_lasso = ### LLENAR: Llene para obtener las predicciones del modelo lasso para el set de TESTEO\n","r2_test_lasso = r2_score(ytest, ytest_predict_lasso)\n","\n","# Finalmente, imprimimos el rendimiento de los modelos\n","#\n","print( f\"El R2 del modelo Ridge en training set es de {r2_train_ridge:5.3f}, y en el test set es de {r2_test_ridge:6.3f}\" )\n","print( f\"El R2 del modelo LASSO en training set es de {r2_train_lasso:5.3f}, y en el test set es de {r2_test_lasso:6.3f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WK2qwoHo7CDf"},"source":["¿Qué cambios observó en el rendimiento de las predicciones al usar regularización? Discuta brevemente (si puede, mencione la relación entre cantidad de datos y cantidad de variables en este problema)"]},{"cell_type":"markdown","metadata":{"id":"nXUdlald-RIt"},"source":["### Interpretabilidad"]},{"cell_type":"markdown","metadata":{"id":"eSvyyoPG714_"},"source":["A veces, uno de los principales objetivos de entrenar un modelo es ver qué variables son más importantes para el mismo. Esto ya lo hicimos \"a ojo\" mirando la matriz de correlación más arriba.\n","\n","Extraiga los coeficientes de los 3 modelos que entrenamos con todas las variables más arriba, para graficar los valores que tienen en el modelo."]},{"cell_type":"code","metadata":{"id":"t7DvyBcHLVnR"},"source":["coefs_regresionLineal = ### RELLENE PARA EXTRAER LOS COEFICIENTES DE LA REGRESION SIN PENALIZACION\n","coefs_regresionRidge = ### RELLENE PARA EXTRAER LOS COEFICIENTES DE LA REGRESION CON PENALIZACION RIDGE\n","coefs_regresionLasso = ### RELLENE PARA EXTRAER LOS COEFICIENTES DE LA REGRESION CON PENALIZACION LASSO\n","\n","# Extraemos los nombres de las variables para identificarlas\n","nombresVariables = boston_dataset.feature_names\n","\n","# Graficamos los coeficientes de la regresion sin penalizacion\n","plt.figure(figsize=(8,10))\n","plt.subplot(3,1,1)\n","plt.plot(coefs_regresionLineal.T,'o')\n","plt.title('Regresion lineal sin penalizacion')\n","plt.grid(True)\n","axis = plt.xticks(ticks=np.arange(13), labels=nombresVariables)\n","\n","# Graficamos los coeficientes de la regresion con penalizacion RIDGE\n","plt.subplot(3,1,2)\n","grafico = plt.plot(coefs_regresionRidge.T,'o')\n","plt.title('Regresion lineal con penalizacion Ridge')\n","plt.grid(True)\n","axis = plt.xticks(ticks=np.arange(13), labels=nombresVariables)\n","\n","# Graficamos los coeficientes de la regresion con penalizacion\n","plt.subplot(3,1,3)\n","inactivos = np.flatnonzero(coefs_regresionLasso == 0)\n","grafico = plt.plot(coefs_regresionLasso.T,'o')\n","plt.plot(inactivos,np.zeros(len(inactivos)),'o',color='gray')\n","plt.title('Regresion lineal con penalizacion Lasso')\n","plt.grid(True)\n","axis = plt.xticks(ticks=np.arange(13), labels=nombresVariables)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HyTqfiANbYWs"},"source":["Compare los coeficientes devueltos por los modelos entre ellos, y comparelos con los que usted eligió al principio. ¿Se ajustan los coeficientes devueltos por los modelos con lo que esperaría a partir de la matriz de correlación? Más arriba usted tuvo que elegir el parámetro de regularización de los modelos (alpha). ¿Cómo cree que cambiarían los resultados según se cambie el alpha? (si quiere pruebe cambiando los parámetros y volviendo a correr el código)."]},{"cell_type":"markdown","metadata":{"id":"jFqgWVKcccbM"},"source":["*Puede insertar sus respuestas aquí:*"]},{"cell_type":"markdown","metadata":{"id":"bvfv0-ZZdUwL"},"source":["**INTENTE COMPLETAR LA PREGUNTA DE ARRIBA ANTES DE PASAR A LA PRÓXIMA**\n","\n","En el código que corrimos arriba, entrenando los modelos y analizando los coeficientes, nos faltó un paso importante ... normalizar los datos!\n","\n","Este paso puede afectar mucho los coeficientes y la interpretabilidad del modelo. Hipotetice sobre el efecto que puede tener el **no** normalizar los datos sobre los coeficientes del modelo (piense en la escala de las diferentes variables que usamos para entrenar el modelo).\n","\n","Vuelva a correr el código de arriba pero incluyendo la normalización de los datos. Tiene un ejemplos de cómo normalizar los datos en el Taller 1 y en el notebook de práctico 2-3. Otra alternativa, muy simple, es usar una opción que tienen las funciones que crean los modelos, que hace que los modelos normalicen automáticamente los datos. Puede mirar cómo implementar esta última alternativa en las páginas de ayuda de las funciones: [help_lr](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html),  [help_ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html), [help_lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html).\n","\n","¿Cómo cambian los coeficientes luego de normalizar los datos?"]},{"cell_type":"markdown","metadata":{"id":"n9ZNK4hiiNBL"},"source":["*Puede insertar sus respuestas aquí:*"]},{"cell_type":"markdown","metadata":{"id":"ImQbVa508pVl"},"source":["## Ejercicio 2 - Arboles de decision\n","\n","### 2.1 - Penguins dataset\n","\n","El [Penguins Dataset](https://github.com/allisonhorst/palmerpenguins) se trata de un dataset con una estructura muy similar a Iris, pero en este caso tenemos 5 caracteristicas para tres especies distintas de pinguinos. Los datos son el sexo del pinguino, largo y ancho del pico (\"bill\" en ingles), largo de la aleta, y peso.\n","\n","A diferencia de el problema anterior, en el que queríamos predecir una cantidad continua, en este problema queremos predecir una clase. Por eso usamos un modelo de *clasificación* para este problema."]},{"cell_type":"code","metadata":{"id":"DpcH1F2v-iT1"},"source":["import seaborn as sns\n","penguins = sns.load_dataset('penguins')\n","print(penguins)\n","penguins = pandas.DataFrame(penguins)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPh_G34COIr6"},"source":["penguins.species = pandas.Categorical(penguins.species)\n","print(penguins.species.cat.categories)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37LqfTNubf1T"},"source":["Los datasets suelen tener caracteristicas no relevadas y estas pueden ser muy problematicas al momento de pasar los datos al modelo para entrenar.\n","\n","Podemos ver si hay datos faltantes para alguna caracteristica usando la funcion *.isnull()* de pandas, y podemos obtener un DataFrame sin los datos faltantes con la funcion *.dropna()*."]},{"cell_type":"code","metadata":{"id":"b7sc1xytcKWB"},"source":["print(\"Cantidad de datos faltantes por categoria:\\n\", penguins.isnull().sum())\n","print(\"----------------------------\")\n","\n","penguins = penguins.dropna() # esta línea es para borrar observaciones que les faltan datos\n","\n","print(\"Cantidad de datos faltantes por categoria luego de usar dropna:\\n\",\n","      penguins.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y3Mlab6rfZjg"},"source":["**Nota auxiliar: Características categóricas**\n","\n","Vemos que el dataset *penguins* tiene un tipo de característica nueva que no hemos visto hasta ahora: las características *island* y *sex* son variables categóricas. La variable *island*, por ejemplo, puede tomar 3 valores distintos, Biscoe, Torgersen, Dream, que no necesariamente siguen un orden claro (ej. no es un valor mayor o menor que el otro).\n","\n","Para incluir una variable categórica en el modelo, en general debemos re-codificarla. Una forma de recodificarla es convertir las clases en números (ej. convertir los valores de *island* en 1, 2, 3), pero esto le da un orden aritificial a los datos. Otra muy utilizada es convertirlas en \"Dummy variables\", una cantidad N de columnas nuevas igual a la cantidad de N valores que puede tomar la variable, con un 1 indicando a dónde pertencece la variable.'\n","\n","Por simplicidad, convertimos la variable *island* en una variable numérica."]},{"cell_type":"markdown","metadata":{"id":"jIExKh86tZUv"},"source":["Abajo convertimos las variables categóricas en variables numéricas, y separamos los datos en set de entrenamiento y de testeo."]},{"cell_type":"code","metadata":{"id":"c7Jrsnrrn6yc"},"source":["# Convertimos island y sex en variables numéricas. En sex, macho=0, hembra=1.\n","penguins['island'], nombresIslas = pandas.factorize(penguins['island'])\n","penguins['sex'] = (penguins['sex'] == \"Female\").astype(int)\n","#\n","# como en el cuaderno 1-3, extraemos los datos y etiquetas\n","#\n","etiquetas = penguins['species'] # extraemos la columna 'species' para hacer la clasificacion\n","y, m = pandas.factorize(etiquetas)\n","X = penguins.drop(['species'], axis=1) # borramos la columna 'species' de la tabla, para obtener el X\n","## y separamos los datos en un set de entrenamiento y otro de testeo\n","Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h1opaRKNuawT"},"source":["Como siempre, antes del análisis visualizamos nuestros datos"]},{"cell_type":"code","metadata":{"id":"PwSBoja-GoIy"},"source":["#\n","# graficamos un scatter plot de los datos\n","grr = pandas_plot.scatter_matrix(Xtrain, c=ytrain, figsize=(10,10))\n","#"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bZzme0D3XxPv"},"source":["Para clasificar la especie de los pinguinos, entrenaremos un árbol de decisión sobre los datos de entrenamiento.\n","\n"]},{"cell_type":"code","metadata":{"id":"1TmhNIcVYvU-"},"source":["from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","\n","arbolDecision = DecisionTreeClassifier()\n","arbolDecision.fit(Xtrain, ytrain)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xfyTqGLpmyeO"},"source":["Ahora quisiéramos ver el rendimiento de modelo en clasificar las especies de pinguinos, tanto en el training set como en el testing set. Escriba abajo el código necesario para ver el rendimiento del modelo *arbolDecision* en el set de entrenamiento y en el set de testeo.\n","\n","**Sugerencia:** La evaluación del rendimiento se puede hacer a mano con la función *.predict*, extrayendo las predicciones para Xtrain, comparando con ytrain y promediando las respuestas (como en el ejemplo del KNN del taller 1). Otra posibilidad es usar la función  *arbolDecision.score*, que hace todos los pasos automáticamente y devuelve la proporción de predicciones correctas. Los parámetros que le tenemos que dar a *.score* son las X que queremos usar, y las *y* correctas para esas X."]},{"cell_type":"code","metadata":{"id":"_duSAAQilpyy"},"source":["# Escriba su código aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jNDKKsblms_d"},"source":["**Regularización en árboles de decisión:** Al igual que los otros métodos que ya vimos, los árboles de decisión también pueden sobreajustarse a los datos. Esto ocurre si permitimos que el modelo haga \"muchas preguntas\", hasta llegar a clasificar correctamente a cada dato de entrenamiento. Hay varios métodos para evitar que los árboles de decisión se sobreajusten. Uno es fijar la profundidad máxima que puede tener el árbol (cuantas \"preguntas\" hace el modelo).\n","\n","En el objeto *DecisionTreeClassifier* que vimos en el cuaderno práctico 2-2, tiene el parámetro *max_depth* que podemos elegir, que marca la máxima profunidad del árbol. Pruebe entrenar y testear un nuevo árbol de decisión abajo, variando el *max_depth*.\n","\n","**Extra 2.1:** Haga lo propuesto arriba, pero usando un loop *for* para iterar entre los valores de *max_depth*"]},{"cell_type":"code","metadata":{"id":"qEe79XPsedg7"},"source":["# Escriba su código aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fz75Qiry8pft"},"source":["### 2.2 - Interpretabilidad\n","\n","Hay muchas maneras de intentar interpretar los algoritmos de clasificacion. Herramientas graficas que nos permitan ver como se separan los datos en una cierta representacion especial pueden ser muy intuitivas en algunos casos. Tambien por lo general es posible calcular coeficientes que expresen la importancia de las caracteristicas de los datos para el modelo.\n","\n","Una herramienta para la interpretacion del arbol de decision podria ser ver graficamente las fronteras que establecio el algoritmo entre los datos. Esto tiene sentido analizarlo particularmente para para cuando se aplica el algoritmo sobre una entrada de dos caracteristicas, ya que la representacion tiene una caracteristica por eje y por lo tanto podemos hacerlo solo hasta 3 caracteristicas (3 dimensiones).\n","\n","Utilizamos la funcion *pintar_regiones* del notebook 2.2 para ver como actua el algoritmo entrenado sobre **pares** de caracteristicas.\n","\n","Elegir un par de caracteristicas que den un buen rendimiento (fundamentar), imprimir la grafica con las regiones de clasificacion pintadas, e interpretar donde esta tomando las fronteras para las ramas, el arbol de decision."]},{"cell_type":"code","metadata":{"id":"mmBcaRNwHdpN"},"source":["caracteristicas = penguins.drop(['species'], axis=1).keys()\n","# Seleccione los pares de variables que quiera usar para ajustar el modelo\n","# Recuerde que las variables posibles son:\n","# 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex'\n","#\n","variablesUsadas = ['bill_length_mm', 'bill_depth_mm'] # MODIFICABLE\n","\n","# Extraemos los índices de las columnas que corresponden a esos nombres, usando list comprehensions\n","indicesUsados = [i for i, val in enumerate(caracteristicas) if val in variablesUsadas]\n","\n","# Con los índices, armamos Xtrain y Xtest incompletos, con sólo las columnas especificadas\n","Xtrain_inc = np.array(Xtrain)[:,indicesUsados]\n","Xtest_inc = np.array(Xtest)[:,indicesUsados]\n","\n","arbolDecision = DecisionTreeClassifier()\n","arbolDecision.fit(Xtrain_inc, ytrain)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1BhTJPW6OAS6"},"source":["import matplotlib.cm as cm\n","from matplotlib.colors import ListedColormap\n","newcolors = [(*c[:3],0.3) for c in cm.RdYlBu(np.linspace(0, 1, 256))]\n","transp = ListedColormap(newcolors)\n","\n","def pintar_regiones(X,y,clasificador,res=100):\n","  '''\n","  pintamos la región de decisión\n","  barremos todo el espacio con una grilla fina y pintamos cada punto\n","  con la clase asignada.\n","  '''\n","  x1s = np.linspace(np.min(X[:,0]),np.max(X[:,0]),100)\n","  x2s = np.linspace(np.min(X[:,1]),np.max(X[:,1]),100)\n","  ns = len(x1s)*len(x2s)\n","  X_aux = np.zeros((ns,2))\n","  i = 0\n","  for x1 in x1s:\n","    for x2 in x2s:\n","      X_aux[i,0] = x1\n","      X_aux[i,1] = x2\n","      i += 1\n","  y_aux = clasificador.predict(X_aux)\n","  #\n","  # grilla fina:\n","  #\n","  plt.scatter(X_aux[:,0],X_aux[:,1],marker='o',edgecolors='none',c=y_aux,s=10,cmap=transp)\n","  #\n","  # puntos de referencia\n","  #\n","  plt.scatter(X[:,0],X[:,1],marker='o',c=y,s=50,cmap=cm.RdYlBu)\n","  plt.title('Región de decisión')\n","  plt.xlabel('Dato 1')\n","  plt.ylabel('Dato 2')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xYi2oQ0RgyF"},"source":["#\n","# ejecutamos función\n","#\n","pintar_regiones(Xtrain_inc,ytrain,arbolDecision)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHG6ywqBULRr"},"source":["En el notebook 2.2 de la clase pasada, vimos codigo que permite dibujar el grafo del arbol de decision usando el paquete _dtreeviz_.\n","\n","Comprobar que el analisis de las regiones de clasificacion anteriormente hecho tenia sentido imprimiendo el grafo.\n","\n","Luego ver como cambia el grafo al hacerlo para el modelo entrenado con **todas** las caracteristicas."]},{"cell_type":"code","metadata":{"id":"fdPRgwJQUtvi"},"source":["# visualización con dtreeviz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97SxHSMZXYOu"},"source":["En funcion de lo observado en las regiones con distintos pares de caracteristicas, y de lo que se ve en el ultimo grafo, que caracteristicas tendran mas importancia? Graficar los *.feature_importances_* del modelo (como fue hecho en el notebook 2.3 de la clase pasada) para ver si estabamos en lo cierto segun la medida de importancia de sklearn."]},{"cell_type":"code","metadata":{"id":"MvcWxKS8XY49"},"source":["# la importancia de cada variable en el arbol de decision"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8q2S0KWvy1k"},"source":["##\n","## DESCOMENTAR PARA GUARDAR PDF!\n","##\n","#%%capture\n","#!apt-get install --quiet texlive-xetex inkscape pandoc texlive-fonts-recommended texlive-generic-recommended\n","#!pip install --quiet nbconvert\n","#!jupyter nbconvert --to pdf /content/drive/MyDrive/Cursos/AABC/Clases/aabc-practico4-1-representacion.ipynb"],"execution_count":null,"outputs":[]}]}