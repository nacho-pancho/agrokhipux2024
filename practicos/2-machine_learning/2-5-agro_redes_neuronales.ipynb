{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytHYFd_U-NSb"
      },
      "source": [
        "# Ejemplo real: detección de uvas en viñedos\n",
        "\n",
        "## Tercer acercamiento: redes neuronales\n",
        "\n",
        "En este notebook continuaremos con el ejemplo de clasificar imágenes de viñedos.\n",
        "Repetimos algunas partes por completitud. Sin embargo, se recomienda fuertemente realizar primero el notebook anterior.\n",
        "\n",
        "## Problema\n",
        "\n",
        "El siguiente problema es un problema real en el que estamos trabajando al momento de dictar este curso.\n",
        "Los datos fueron extraídos de un viñedo en Uruguay y procesados por nosotros.\n",
        "\n",
        "* A diferencia de lo que hicimos antes, en lugar de mirar pixel a pixel, vamos a mirar _regiones_ de pixeles.\n",
        "* Para determinar la clase de un pixel, estudiaremos la región que lo circunda.\n",
        "* Las regiones que vamos a considerar son _patches_ (_parches_  en inglés) cuadrados de tamaño $w{\\times}w$, con $w$ impar, centrados en el pixel _objetivo_.\n",
        "* Lo anterior implica que nuestro modelo pasa de tener una entrada de $3$ valores (rojo, verde, azul) a una entrada de $3{\\times}m$ valores, en donde $m=w^2$ es la cantidad de puntos en la región a analizar.\n",
        "* Para analizar dichas regiones vamos a usar una _red neuronal convolucional_. \n",
        "* Para esta parte es necesario contar con una GPU y la biblioteca _Pytorch_ funcionando en el entorno de Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datos\n",
        "\n",
        "Las imágenes son fotos de uvas en viñedos. Cada imagen está acompañada de una máscara que indica si un pixel es \"uva\" o no.\n",
        "\n",
        "### Descarga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from urllib import request\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "remote_url=\"https://iie.fing.edu.uy/dps/datos/publico/vino/vino_fino/masks/2024-03-04-vino_fino_sector_0-1.zip\"\n",
        "local_file=\"vino_fino_train.zip\"\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "with ZipFile(local_file, 'r') as zf:\n",
        "    zf.extractall(\"train\")\n",
        "\n",
        "remote_url=\"https://iie.fing.edu.uy/dps/datos/publico/vino/vino_fino/masks/2024-03-04-vino_fino_sector_122_123.zip\"\n",
        "local_file=\"vino_fino_test.zip\"\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "with ZipFile(local_file, 'r') as zf:\n",
        "    zf.extractall(\"test\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga en memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import skimage.io as imgio\n",
        "import numpy as np\n",
        "\n",
        "def cargar_imagenes():\n",
        "    #\n",
        "    # armamos listas de imágenes y sus máscaras\n",
        "    #\n",
        "    train_image_list = glob.glob(\"train/2024-03-04-vino_fino_sector_0-1/images/*.png\")\n",
        "    train_mask_list = sorted([i for i in train_image_list if \"mask\" in i])\n",
        "    train_image_list = sorted([i for i in train_image_list if \"mask\" not in i])\n",
        "    ntrain = len(train_image_list)\n",
        "    assert(len(train_mask_list) == ntrain)\n",
        "    print('Imagenes de entrenamiento:',ntrain)\n",
        "\n",
        "    test_image_list = glob.glob(\"test/2024-03-04-vino_fino_sector_122_123/images/*.png\")\n",
        "    test_mask_list  = sorted([i for i in test_image_list if \"mask\" in i])\n",
        "    test_image_list = sorted([i for i in test_image_list if \"mask\" not in i])\n",
        "    ntest = len(test_image_list)\n",
        "    assert(len(test_mask_list) == ntest)\n",
        "    print('Imagenes de evaluacion:',ntest)\n",
        "\n",
        "    #\n",
        "    # cargamos las imágenes en memoria\n",
        "    train_images = [(imgio.imread(i)/255).astype(np.float32) for i in train_image_list]\n",
        "    train_masks  = [(imgio.imread(i)/255).astype(np.float32) for i in train_mask_list]\n",
        "\n",
        "    test_images = [(imgio.imread(i)/255).astype(np.float32) for i in test_image_list]\n",
        "    test_masks  = [(imgio.imread(i)/255).astype(np.float32) for i in test_mask_list]\n",
        "\n",
        "    #\n",
        "    # le recortamos un poco arriba y abajo para ahorrar\n",
        "    # cómputo y porque no hay nada ahí.\n",
        "    #\n",
        "    crop = train_images[0].shape[0]//5\n",
        "\n",
        "    train_images = [i[crop:-crop,:,:] for i in train_images]\n",
        "    train_masks  = [i[crop:-crop,:] for i in train_masks]\n",
        "\n",
        "    test_images = [i[crop:-crop,:,:] for i in test_images]\n",
        "    test_masks  = [i[crop:-crop,:] for i in test_masks]\n",
        "    return train_images,train_masks,test_images,test_masks\n",
        "\n",
        "\n",
        "train_images,train_masks,test_images,test_masks = cargar_imagenes()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Muestra de ejemplo\n",
        "\n",
        "Veamos abajo algunas de las imágenes que cargamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as rng\n",
        "\n",
        "mpl.rcParams['figure.dpi'] = 100\n",
        "mpl.rcParams['savefig.dpi'] = 150\n",
        "\n",
        "mpl.rcParams['font.size'] = 10\n",
        "mpl.rcParams['legend.fontsize'] = 'small'\n",
        "mpl.rcParams['figure.titlesize'] = 'small'\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,8),facecolor=(0.3,0.3,0.3))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(train_images[0])\n",
        "plt.title('Imagen')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(train_masks[0],cmap='hot')\n",
        "plt.title('Mascara')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## PyTorch\n",
        "\n",
        "PyTorch es una biblioteca muy popular y sofisticada para crear y entrenar modelos neuronales complejos.\n",
        "En nuestro caso, los datos de entrada son _parches_ (patches) de imágenes: pequeños cuadrados de tamaño $w{\\times}w$. Nosotros vamos a usar un tamaño que sea semejante al de una uva promedio en nuestras imágenes: $w=21$.\n",
        "\n",
        "Las redes convolucionales (CNN) son un tipo de arquitectura de red neuronal que se utiliza mucho en análisis de imágenes. Una propiedad importante de las CNN es su _campo receptivo_, es decir, el tamaño de parche sobre el que realiza la inferencia. Este valor se determina de la arquitectura de la red. En el ejemplo que veremos abajo, lograremos esto mediante dos capas convolucionales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga de datos en PyTorch\n",
        "\n",
        "Debido a su complejidad, es necesario implementar algunas estructuras auxiliares para alimentar los algoritmos de PyTorch.\n",
        "Concretamente, esto se hace mediante _clases_  llamadas `DataLoader` y `DataSet`. \n",
        "\n",
        "Además de cargar las imágenes de esta manera, las imágenes a color (RGB o lo que sea, con varios canales de color) deben ser ingresadas de una manera particular. En general, en las bibliotecas de imágenes y dibujo de Python, las imágenes a color son un arreglo (Tensor) de la forma _ancho x largo x canales_ donde _canales_  es 3 (rojo, verde, azul).\n",
        "\n",
        "En PyTorch, se asume que las imágenes tienen la forma _canales x ancho x largo_. Entonces hay que transponerlas de manera que queden de esa manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self,images,masks):\n",
        "        padding = transforms.Pad(6) # 3 veces el radio del kernel, que es 2 (5-1/2, ver abajo en la def. de la red)\n",
        "        H,W,C = images[0].shape\n",
        "        self.images = list(padding(torch.tensor(i.transpose((2,0,1)),dtype=torch.float32)) for i in images)\n",
        "        self.masks = list(torch.tensor(i.reshape(H,W),dtype=torch.long) for i in masks)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.images[idx],self.masks[idx]\n",
        "\n",
        "train_dataset = ImageDataset(train_images,train_masks)\n",
        "test_dataset = ImageDataset(test_images,test_masks)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size=1,shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definición del modelo neuronal\n",
        "\n",
        "Abajo vemos cómo se construye el modelo que vamos a usar.\n",
        "PENDIENTE: explicarlo mejor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as fun\n",
        "\n",
        "ancho_patch = 5\n",
        "dim_patch = ancho_patch*ancho_patch\n",
        "canales_0 = 3 # RGB\n",
        "canales_1 = 16\n",
        "canales_2 = 16\n",
        "canales_3 = 2 # clase\n",
        "clases = 1\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(canales_0, canales_1, ancho_patch)       # primera capa, mira parches de 5x5 de 6 maneras distintas (filtros)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)        # esto reduce la dimensión a la mitad, lo que aumenta el campo receptivo al doble (10x10)\n",
        "        self.conv2 = nn.Conv2d(canales_1, canales_2, ancho_patch)      # nuevamente, miramos parches de 5x5, pero ahora de 16 maneras distintas\n",
        "        self.pool2 = nn.MaxPool2d(2,2)        # esto reduce la dimensión a la mitad, lo que aumenta el campo receptivo al doble (5x5)\n",
        "        self.conv3 = nn.Conv2d(canales_2, canales_3, ancho_patch)      # nuevamente, miramos parches de 5x5, pero ahora de 2 maneras distintas\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.pool1(fun.relu(self.conv1(x)))\n",
        "        #x = self.pool2(fun.relu(self.conv2(x)))\n",
        "        x = fun.relu(self.conv1(x))\n",
        "        x = fun.relu(self.conv2(x))\n",
        "        x = fun.softmax(self.conv3(x),dim=0)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.2,0.8],dtype=torch.float32))\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "ntrain = len(train_dataset)\n",
        "\n",
        "prev_loss = 1\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    avg_loss = 0.0\n",
        "    tol = 1e-3\n",
        "    for j in range(ntrain):\n",
        "        input,target = train_dataset.__getitem__(j)        \n",
        "        output = net(input)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output.reshape((1,*output.shape)),target.reshape(1,*target.shape))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_value = loss.item()\n",
        "        avg_loss += loss_value\n",
        "    avg_loss /= ntrain\n",
        "    change = abs(avg_loss-prev_loss)/(1e-10+avg_loss) \n",
        "    print(f'[epoch {epoch + 1} training loss: {avg_loss:.5f} prev {prev_loss:.5f} change {change:.8f}')\n",
        "    if change < tol:\n",
        "        print('no further improvement.')\n",
        "        break\n",
        "    prev_loss = avg_loss\n",
        "print('finished training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluacion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval(test_images,test_masks,predicted_masks):\n",
        "    for j,I in enumerate(test_images):\n",
        "        M,N,C = I.shape\n",
        "        X = np.reshape(I,(M*N,C))\n",
        "        true_mask = test_masks[j]\n",
        "        pred_mask = predicted_masks[j]\n",
        "        score = np.mean(np.abs(true_mask-pred_mask))\n",
        "        print(f'imagen {j} score {score:.4f}')\n",
        "        plt.figure(figsize=(12,5),facecolor=(0.3,0.3,0.3))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(true_mask,cmap='hot')\n",
        "        plt.title('Mascara real')\n",
        "        plt.colorbar()\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(pred_mask,cmap='hot')\n",
        "        plt.title('Mascara predicha')\n",
        "        plt.axis('off')\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "def apply(test_dataset):\n",
        "    ntest = len(test_dataset)\n",
        "    predicted_masks = []\n",
        "    for j in range(ntest):\n",
        "        input,target = test_dataset.__getitem__(j)\n",
        "        output = net(input)        \n",
        "        loss = criterion(output.reshape((1,*output.shape)),target.reshape(1,*target.shape))\n",
        "        print('image',j,'loss',loss.item())\n",
        "        predicted_masks.append(output.detach().numpy())\n",
        "    return predicted_masks\n",
        "\n",
        "\n",
        "pred_masks = apply(test_dataset)\n",
        "pred_masks = [i[1,:,:].squeeze()>0.5 for i in pred_masks] # de logit a clase\n",
        "eval(test_images,test_masks,pred_masks)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
