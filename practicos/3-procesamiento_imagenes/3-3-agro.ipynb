{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytHYFd_U-NSb"
      },
      "source": [
        "## Carga de imágenes\n",
        "\n",
        "\n",
        "git@github.com:guiwitz/PyImageCourse_beginner.git\n",
        "\n",
        "\n",
        "Puse un par de ejemplos que mandó Marcel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jQEi5gjrwDhz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#from scipy import cluster\n",
        "from sklearn.cluster import KMeans,DBSCAN\n",
        "import skimage.io as imgio\n",
        "import skimage.color as imgcolor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T67EhLnl-Ujw"
      },
      "source": [
        "## Carga y recorte\n",
        "\n",
        "La imagen es una versión reducida a 1/4 en cadad dimensión (1/16 de pixeles). En realidad creo que se puede reducir aún más sin afectar los resultados.\n",
        "\n",
        "Además no nos interesa la parte de más abajo, que siempre va a ser tierra y el tallo (creo).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RvLBxBORxeib"
      },
      "outputs": [],
      "source": [
        "Irgb = imgio.imread('http://iie.fing.edu.uy/~nacho/cursos/agro/frame_crudo.jpg')\n",
        "\n",
        "\n",
        "downsample = 4\n",
        "\n",
        "Irgb =(Irgb[:-250:downsample,::downsample,:]/255).astype(float) # a la mitad en cada dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHNW5ITk-sTN"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "Transformamos la imagen a HSV. Esta transformación _no lineal_ (eso es importante, porque modifica las distancias en el espacio) es más acorde a la percepción humana. No es que eso sea necesario en este caso, pero al parecer el tono de las uvas es algo distintivo. Podría no usarse y hacerse sólo con la imagen original en RGB también.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXUc7idaxi0J"
      },
      "outputs": [],
      "source": [
        "Ihsv = imgcolor.rgb2hsv(Irgb)\n",
        "Ihv  = Ihsv[:,:,::2] # canales 0 y 2\n",
        "Ih   = Ihsv[:,:,0]\n",
        "#\n",
        "# vemos algunos ejemplos de distintas representaciones y sus canales\n",
        "#\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(Irgb)\n",
        "plt.axis('off')\n",
        "plt.title('RGB')\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(Ihsv[:,:,0])\n",
        "plt.axis('off')\n",
        "plt.title('Hue')\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(Ihsv[:,:,1])\n",
        "plt.axis('off')\n",
        "plt.title('Saturation')\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(Ihsv[:,:,2])\n",
        "plt.axis('off')\n",
        "plt.title('Value')\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "# cantidad de clusters (modificable)\n",
        "#\n",
        "M,N,C = Irgb.shape\n",
        "#\n",
        "# datos: aquí podemos elegir entre distintas representaciones\n",
        "# descomentar la que se quiera usar\n",
        "#\n",
        "#Xrgb = np.reshape(Irgb,(M*N,C)).astype(float) # 1 dato = vector RGB\n",
        "#Xhsv = np.reshape(Ihsv,(M*N,C)) # 1 dato = vector HSV\n",
        "Xhv  = np.reshape(Ihsv[:,:,0::2],(M*N,2)) # 1 dato = solo Hue (tono) y valor (brillo)\n",
        "Xrb  = np.reshape(Irgb[:,:,0::2],(M*N,2)) # 1 dato = solo Hue (tono) y valor (brillo)\n",
        "#Xh   = np.ravel(Ihsv[:,:,0])    # 1 dato = Hue (tono)\n",
        "#\n",
        "# cambiar aquí según el espacio que se quiera usar\n",
        "#\n",
        "X = Xhv\n",
        "print(np.max(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdiw8covCER6"
      },
      "source": [
        "### Comentarios\n",
        "\n",
        "Se puede ver que las uvas se distinguen particularmente en los canales Hue y Value. La saturación no aporta nada en este caso.\n",
        "\n",
        "Tiene sentido entonces quedarse sólo con los canales Hue y Value.\n",
        "\n",
        "### Exploración de estos canales\n",
        "\n",
        "Vamos a ver los pixeles en el espacio H-V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fDwI3YyDaIr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Xhv[:,0],Xhv[:,1],s=2,alpha=0.25)\n",
        "plt.xlabel('hue')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BR437w3FyY4"
      },
      "source": [
        "### Observaciones\n",
        "\n",
        "Se ven tres grupos claros con forma de \"cluster\" propiamente dicha.\n",
        "\n",
        "Los tres grupos corresponden, al parecer, a tres cosas: lo verde (pasto y hojas) que sería el grupo grande de la izquierda; el cielo, y algunas cosas brillantes, que serían el grupo de arriba, y las uvas, que serían el grupo de más a la izquierda. Hay algo que creo que tiene que ver con las uvas y son las bandas verticales gruesas, que supongo que se deben a los distintos colores de uva (algunos son más rojizos, otros más violetas).\n",
        "Vamos a ver luego cómo se arman los clusters en base a esta estructura.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T-tvwnEl0D6l"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# el algoritmo kmeans devuelve una asignación de clase para cada dato\n",
        "# esto puede variar según la semilla usada; el no. de clase es irrelevante\n",
        "#\n",
        "k = 3\n",
        "color_1 = (0.2,0.5)\n",
        "color_2 = (0.57,1.0) # cielo\n",
        "color_3 = (0.8,0.25) # uvas\n",
        "ini_cb = np.array((color_1,color_2,color_3))\n",
        "\n",
        "np.random.seed(42)\n",
        "model = KMeans(n_clusters=3,init=ini_cb,n_init=1)\n",
        "Xvq_class = model.fit_predict(X)\n",
        "Ivq = np.reshape(Xvq_class,Ihsv.shape[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of-xaCBr1e1P"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# resultados\n",
        "#\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Irgb)\n",
        "plt.axis('off')\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(Ivq/k,cmap='jet')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(X[:,0],X[:,1],s=2,alpha=0.25,c=Xvq_class/k)\n",
        "plt.xlabel('hue')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OazahUI9Gy0u"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwpEG8e3vZC9"
      },
      "source": [
        "\n",
        "### Comentarios\n",
        "\n",
        "El K-means anda horrible porque los puntos en el espacio no están claramente separados. Si noestuvieran las lineas verticales, o talvez inicializando con otra semilla, sería más fácil. También se podría usar un método más robusto tipo k-medians, o spectral clustering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHFxHlRqvadZ"
      },
      "source": [
        "## Otros métodos\n",
        "\n",
        "Vamos a probar con un método más moderno a ver qué pasa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URWlB9RUvdY1"
      },
      "outputs": [],
      "source": [
        "from sklearn import cluster\n",
        "from sklearn import mixture\n",
        "k = 3\n",
        "print('number of samples',len(X))\n",
        "np.random.seed(42)\n",
        "#model = cluster.OPTICS() # no da la memoria!\n",
        "#model = cluster.DBSCAN() # no da la memoria!\n",
        "#model = cluster.SpectralClustering() # no da tampoco\n",
        "#model = cluster.AgglomerativeClustering()\n",
        "#model = cluster.KMeans(n_clusters=3,n_init=10)\n",
        "#model = mixture.GaussianMixture(n_components=4)\n",
        "#model = cluster.AgglomerativeClustering(memory=\"./ag\")\n",
        "Xvq_class = model.fit_predict(X)\n",
        "\n",
        "Ivq_class = np.reshape(Xvq_class,(M,N)).astype(float)\n",
        "kauto = np.max(Xvq_class)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Irgb.astype(np.uint8))\n",
        "plt.axis('off')\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(Ivq_class/k,cmap='jet')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,8))\n",
        "plt.scatter(X[:,0],X[:,1],s=2,alpha=0.25,c=Xvq_class/k)\n",
        "plt.xlabel('hue')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUIWtAUzIYTF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Clustering manual\n",
        "\n",
        "También podemos, con información a priori y asumiendo que las imágenes se toman en condiciones similares, fijar los centroides nosotros y ver qué pasa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DG8E4-wI9Xf"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster import vq\n",
        "color_1 = (0.2,0.5)\n",
        "color_2 = (0.57,1.0) # cielo\n",
        "color_3 = (0.8,0.25) # uvas\n",
        "codebook_manual = np.array((color_1,color_2,color_3))\n",
        "print(np.max(X))\n",
        "Xvq_manual,_    = vq.vq(X,codebook_manual)\n",
        "Ivq_manual      = np.reshape(Xvq_manual,(M,N)).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTt2Oip4JvZL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,12))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Irgb.astype(np.uint8))\n",
        "plt.axis('off')\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(Ivq_manual/k,cmap='jet')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,8))\n",
        "plt.scatter(X[:,0],X[:,1],s=2,alpha=0.25,c=Xvq_manual/3)\n",
        "plt.xlabel('hue')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWV-DnQKKDpY"
      },
      "source": [
        "## Regularización espacial\n",
        "\n",
        "Como se ve, y es de esperar, hay confusiones en los bordes, que suelen tener colores mezclados.\n",
        "\n",
        "Para eliminar esto podemos hacer un filtro de mediana de la imagen de clases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK1Z28g5KVUM"
      },
      "outputs": [],
      "source": [
        "from skimage import filters\n",
        "\n",
        "Ivq_manual_med = filters.median(Ivq_manual,footprint=np.ones((13,13)))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Irgb)\n",
        "plt.axis('off')\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(Ivq_manual_med/k,cmap='jet')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCOokG4UMjti"
      },
      "source": [
        "## Medición\n",
        "\n",
        "Claro que se puede aprender, pero se me ocurre que una buena función a aplicar a la cantidad de pixeles de uvas para estimar el yield es $y=x^{3/2}$. Por qué? Porque lo que vemos es aproximadamente un área, que se relaciona con el diámetro (longitud) en una relación $\\mathrm{area}\\propto\\mathrm{diametro}^2$. El volumen se relaciona $\\mathrm{volumen}\\propto\\mathrm{diametro}^3$. Entonces la relación área-volumen es $\\mathrm{volumen}\\propto\\mathrm{area}^{3/2}$.\n",
        "\n",
        "El clustering manual tiene dos ventajas:\n",
        "\n",
        "* Sirve para inicializar un algoritmo automático, como K-means\n",
        "* Ya nos dice qué cluster corresponde a las uvas. En el caso de arriba, es el 3 (índice 2).\n",
        "\n",
        "Claro que el \"yield\" que obtenemos abajo es en pixeles, claramente no es la medida correcta. Habría que hacer una regresión para relacionarlo con el valor de interés.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F5LpAHdNay8"
      },
      "outputs": [],
      "source": [
        "yield_area = len(np.flatnonzero(Xvq_manual==2))\n",
        "print(yield_area)\n",
        "\n",
        "yield_vol = yield_area**(3/2)\n",
        "\n",
        "print(yield_vol)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
