{"cells":[{"cell_type":"markdown","metadata":{"id":"F5jeadS03zst"},"source":["# Práctico 1-3: Primer ejemplo de aprendizaje automático\n","\n","\n","## Clasificación de especies del género *Iris*\n","\n","Este es un problema clásico de aprendizaje supervisado. El objetivo es entrenar un sistema para que sea capaz de identificar automáticamente a qué especie pertenece una flor dado un conjunto de características morfológicas de ella:\n","\n","*   largo del pétalo\n","*   ancho del pétalo\n","*   largo del sépalo\n","*   ancho del sépalo\n","\n","Para _entrenar_ el sistema tenemos una colección de 150 especímenes. De cada especimen tenemos las 4 medidas y también sabemos a ciencia cierta a cuál especie pertenece.\n","\n","El paquete `scikit-learn` ya viene con un conjunto de datos clásicos para fines pedagógicos. Vamos a cargar estos datos\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1697470382924,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"98v9Dajn7kNc","outputId":"0d3cde1e-bd68-44a6-a38a-3643e901ab85"},"outputs":[],"source":["#\n","# sub paquete datasets contiene conjuntos de datos clásicos\n","#\n","from sklearn import datasets\n","#\n","# cargamos los datos de IRIS\n","#\n","iris_dataset = datasets.load_iris()\n","#\n","# los datasets de sklearn son un diccionario de Python\n","# vemos qué tiene adentro\n","#\n","print('Contenido del dataset:\\n', iris_dataset.keys() )\n","#\n","# DESCR tiene una descripción textual del dataset:\n","#\n","print('Descripción:\\n',iris_dataset['DESCR'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1697470382925,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"cDGtFb8p3DCd","outputId":"cecf2c51-1154-4ea8-c0b8-ed46470191d8"},"outputs":[],"source":["#\n","# la clave (key) 'target_names' es una lista de cadenas de texto\n","# cada una contiene los nombres de las especies que queremos\n","# predecir; estas son las 'clases' en nuestro problema de clasificación\n","#\n","especies = iris_dataset['target_names']\n","print('Clases (especies):\\n', especies)\n","#\n","# la clave 'feature_names' provee un nombre para cada característica (feature)\n","# relevada.\n","#\n","caracteristicas = iris_dataset['feature_names']\n","print('\\nCaracterísticas (medidas):\\n',caracteristicas)\n","#\n","# la clave 'data' es la que contiene los valores de las características\n","#  de cada una de las 150 muestras disponibles en forma de matriz.\n","#\n","# cada fila de la matriz corresponde a un especimen\n","# cada dato es un vector con los valores de las 4 medidas\n","#\n","print('\\nMuestras:')\n","\n","muestras = iris_dataset['data']\n","nfilas,ncolumnas = muestras.shape\n","print('\\tCantidad de muestras:',nfilas)\n","print('\\tMedidas por muestra:',ncolumnas)\n","#\n","# veamos los primeros 5 datos\n","# notar la sintaxis para especificar las primeras 5 filas de la matriz\n","#\n","# siempre es bueno inspeccionar visualmente, aunque sean sólo números,\n","# los datos que se van a utilizar\n","#\n","# en este caso vemos que las primeras 5 muestras tienen todas el mismo ancho\n","# de pétalo (0.2cm)\n","#\n","print('\\nPrimeras 5 filas:\\n', muestras[:5,:] )\n","\n","#\n","# finalmente tenemos 'target', que contiene la especie correspondiente\n","# a cada muestra; esto es un arreglo (array) de 150 elementos\n","# correspondientes a las 150 filas del campo 'data'\n","#\n","# la especie se codifica con un número de 0 a 2 en este caso.\n","# cada uno de esos 3 valores se corresponde con una especie.\n","#\n","# dado el número, podemos ver a qué especie corresponde usando\n","# el campo iris_dataset['target_names'], que ya vimos.\n","#\n","# Por ejemplo, el número 0 se corresponde con 'setosa'\n","#\n","# Al dato que indica a qué clase pertenece cáda muestra lo llamamos usualmente\n","# 'etiqueta' (label en inglés)\n","#\n","etiquetas = iris_dataset['target']\n","print('\\nEtiquetas:\\n',etiquetas)\n"]},{"cell_type":"markdown","metadata":{"id":"mT3w4gDJC7Qh"},"source":["## Midiendo el desempeño: datos de entrenamiento y de prueba (test)\n","\n","Ahora que tenemos las muestras, y sabemos a qué especie pertenece cada una, queremos construir un sistema que aprenda de eso para luego ser capaz de inferir la especie de nuevas flores que veamos a partir de sus medidas.\n","\n","Para eso, necesitamos tener una medida de qué tan bueno es nuestro sistema para inferir especies.\n","\n","El tema es que no podemos evaluar el desempeño de nuestro sistema con  los mismos datos que usamos para entrenarlo. Si hiciéramos eso, el mejor sistema posible sería siempre el que simplemente recuerde a qué especie pertenece cada muestra; eso no sería aprender, sino memorizar.\n","\n","Para evaluar el desempeño, necesitamos saber qué tan bueno es nuestro sistemas para inferir la especie de muestras _nunca_ vistas antes en el entrenamiento.\n","\n","La idea es separar nuestro conjunto de datos en dos partes: uno de _entrenamiento_ (training) y otro de _prueba_ (test). El primer conjunto es utilizado para enseñarle al sistema.\n","\n","Luego de entrenado el sistema, presentamos a éste las muestras del conjunto de prueba y cotejamos la especie inferida por el sistema por la especie _correcta_, que conocemos de antemano.\n","\n","Veremos ahora cómo armar estos subconjuntos con las utilidades de `scikit-learn`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1697470382926,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"7oG26yh5QgGE","outputId":"831641b5-efc8-4843-b7a6-ffe4b2143c91"},"outputs":[],"source":["from sklearn import model_selection\n","#\n","# para abreviar,\n","# llamamos 'X' a las muestras e 'y' a las etiquetas\n","#\n","# la función train_test_split, por defecto, separa 75% de los datos\n","# (tomados al azar) para entrenamiento, y el 25% para prueba\n","#\n","Xtrain, Xtest, ytrain,ytest = model_selection.train_test_split(muestras,etiquetas)\n","#\n","# veamos los tamaños\n","#\n","print('Cantidad de datos de entrenamiento:',len(ytrain))\n","print('Cantidad de datos de prueba       :',len(ytest))\n","#\n"]},{"cell_type":"markdown","metadata":{"id":"t4oLfQSmTNUT"},"source":["## Inspección visual\n","\n","Siempre es buena idea inspeccionar los datos visualmente antes de empezar a trabajar. De esa manera podemos adquirir intuición sobre el problema, posibles patrones y particularidades que podemos explotar para construir un sistema más efectivo.\n","\n","La forma más natural de ver los datos es un puntillado (scatter plot) en donde\n"," cada muestra es presentada en el espacio como un punto.\n","\n","El mayor problema que suele presentarse a esta altura es que nosotros los humanos no tenemos una forma efectiva de visualizar datos en más de 2 (talvez 3) dimensiones, lo cual suele ser bastante menos que la dimensión de los datos (en nuestro caso 4).\n","\n","Lo que podemos hacer, por ejemplo, es mirar los datos de a pares de coordenadas,\n"," es decir, si tenemos 4 coordenadas (a,b,c,d), podemos pintar los datos  en el plano mirando sólamente a y b, luego a y c, luego a y d, luego b y c, etc.\n","\n","### Pandas\n","\n","Aquí vamos a usar la biblioteca **Pandas**. Esta biblioteca permite trabajar con datos de una manera similar a como lo hace el lenguaje R, es decir, a un nivel de abstracción mayor: mientras que en NumPy los datos son simplemente matrices numéricas (o de texto), en Pandas (y en R) se trabaja con _tablas_. En las tablas, las filas y las columnas tienen nombre, es decir, tienen un significado intrínseco. El nombre que se le da a estas tablas en Pandas es `DataFrame`. Veremos ahora cómo armar una tabla de datos en Pandas, y usaremos sus funcionalidades para visualizar los datos que queremos clasificar.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":843},"executionInfo":{"elapsed":3521,"status":"ok","timestamp":1697470386438,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"RrZ_rBXqUWXo","outputId":"ac66791b-3148-437b-fd75-3fbb9ef9ff65"},"outputs":[],"source":["# paquete principal\n","import pandas\n","# subpaquete para dibujar\n","from pandas import plotting as pandas_plot\n","#\n","# creamos una tabla con los datos de entrenamiento de iris,\n","# dando el nombre correspondiente a cada columna\n","#\n","tabla_iris = pandas.DataFrame(Xtrain,columns=iris_dataset.feature_names)\n","#\n","# la función scatter_matrix muestra un mosaico de gráficas  en donde cada\n","# gráfica fuera de la diagonal es la nube de puntos obtenida en base a\n","# dos medidas distintas.\n","# En la diagonal se muestran los histogramas de cada medida\n","# El color de cada punto (argumento 'c' de scatter_matrix) se define\n","# según la etiqueta del dato correspondiente.\n","#\n","# (NOTA: el libro usa una versión vieja de Pandas;\n","# la forma correcta es la siguiente)\n","\n","grr = pandas_plot.scatter_matrix(tabla_iris, c=ytrain, figsize=(10,10))"]},{"cell_type":"markdown","metadata":{"id":"8W7NFQA2WrlK"},"source":["De inspeccionar los datos podemos sacar algunas conclusiones. Por ejemplo, en casi todos los casos vemos que alcanza con dos características para separar bien una de las clases (violeta) de las otras dos. Ya las otras dos están bastante pegadas en la mayoría de los casos, llegando a mezclarse mucho por ejemplo si sólo consideramos el ancho y el largo de los sépalos (segunda fila a la izquierda).\n"]},{"cell_type":"markdown","metadata":{"id":"9Tzf1exMXRQx"},"source":["# Primer modelo: k-NN\n","\n","En este momento es que comienzan las decisiones técnicas. Hay muchos métodos posibles para entrenar un sistema de clasificación para este problema.\n","\n","Nuestro primer modelo es el llamado _k vecinos más cercanos_. Este es un método muy simple y consiste en lo siguiente: para inferir la etiqueta de una nueva muestra, ubicamos el punto $x_0$ correspondiente a esta muestra en el espacio de caracerísticas (en nuestro caso, un espacio de 4 dimensiones). Luego miramos a qué clase (en nuestro caso, especie) pertenecen los $k$ puntos vecinos más cercanos  a $x_0$ en el espacio, y resolvemos que la clase de nuestro nuevo punto es la más frecuente entre los $k$ vecinos (si hay un empate, elegimos al azar entre las mayoritarias).\n","En el caso más sencillo, miramos un sólo vecino (1-nn) y resolvemos que esa también es la clase de nuestra nueva muestra $x_0$.\n","\n","A pesar de la sencillez de este método, tanto conceptual como algorítmica (de hecho no hay ajuste de parámetros; simplemente se memoriza el conjunto de entrenamiento), el $k-nn$ puede y suele ser suficiente para muchos problemas.\n","\n","Pongamos esto en marcha usando `sklearn`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1697470386439,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"ulse-6F1Zy6w","outputId":"718b6f23-9ce4-4d74-c614-4e02bd4763a7"},"outputs":[],"source":["#\n","# traemos el clasificador correspondiente de sklearn\n","#\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","#\n","# creamos un clasificador k-nn con k (n_neighbors) = 1\n","#\n","# la variable knn no es un número, ni texto:\n","# es lo que se llama un 'objeto' de tipo 'KNeighborsClassifier'\n","# más que variable, es como un conjunto de variables bajo un mismo nombre\n","# que además tiene funciones asociadas.\n","#\n","knn = KNeighborsClassifier(n_neighbors=1) # k = 1\n","#\n","# ajustamos (fit) el modelo a los datos de _entrenamiento_\n","#\n","# esto no produce un resultado hacia 'afuera', sino que modifica\n","# internamente el _estado_ del objeto\n","#\n","knn.fit(Xtrain,ytrain)\n","#\n","# listo, ahora podemos usar nuestro modelo para inferir\n","# la especie de un dato nuevo\n","#\n","# aunque sea solo un dato, los clasificadores de SKLearn\n","# siempre espera que se les pase una matriz donde\n","# cada fila es un dato, así que tenemos que armar una matriz\n","# de 1 x 4 y poner nuestro dato en la primera (y única) fila\n","Xnuevo = np.array([\n","                   [5.0, 2.9, 1.0, 0.2]\n","                   ])\n","ynuevo = knn.predict(Xnuevo)\n","enuevo = especies[ynuevo]\n","print(f'Especie inferida: etiqueta {ynuevo}, correspondiente a especie {enuevo}')\n"]},{"cell_type":"markdown","metadata":{"id":"p1ZPllRrdWMT"},"source":["# Evaluación de desempeño\n","\n","Tenemos un sistema que dada una nueva muestra es capaz de inferir la especie de la flor. Sin embargo, no tenemos información aún para _confiar_ en ese resultado.\n","Para eso es que vamos a usar el conjunto de _prueba_. En ese conjunto, que el sistema nunca vio, sabemos de antemano a qué especie pertenece cada muestra. Lo que hacemos ahora es tomarle un examen al clasificador: lo hacemos inferir la especie de cada muestra, y cotejamos su decisión con la decisión correcta que ya conocemos.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1697470386440,"user":{"displayName":"Mauricio Langleib","userId":"00337117213148150390"},"user_tz":180},"id":"U5fH6QCkd6KA","outputId":"f151e2f5-4f14-4f87-b5be-1bae8a0e1325"},"outputs":[],"source":["#\n","# vemos qué arroja el clasificador para cada dato de prueba\n","#\n","ytest_segun_knn = knn.predict(Xtest) # lo que infiere k-NN\n","ytest_posta = ytest # los que sabíamos de antemano\n","\n","print('\\nEtiquetas inferidas sobre el conjunto de prueba:\\n',ytest_segun_knn)\n","#\n","# cotejamos con las etiquetas correctas\n","# el operador == es un operador de _comparación_:\n","# a == b devuelve el valor booleano True si a y b son idénticos,\n","# y False si no lo son.\n","#\n","# NO CONFUNDIR con operador '='. Un sólo '=' se usa para *asignar*,\n","# es decir, para darle valor a una cosa (ej., una variable)!\n","#\n","# si usamos == sobre dos listas del mismo largo en NumPy\n","# obtendremos una lista del mismo largo donde cada elemento corresponde a la\n","# comparación entre los dos elementos correspondientes de las listas comparadas.\n","#\n","#\n","es_correcto = (ytest_segun_knn == ytest_posta)\n","#\n","# el desempeño es simplemente el porcentaje de datos de prueba en donde\n","# el k-NN produjo el valor correcto.\n","#\n","# Como NumPy permite interpretar vectores booleanos como números (True -> 1, False ->0)\n","# el porcentaje lo obtenemos simplemente como el promedio de 'es_correcto'\n","# para hacer promedios tenemos la función 'mean' de NumPy.\n","#\n","score = 100*np.mean(es_correcto) # porcentaje: 100 x fracción de inferencias correctas\n","score = np.round(score) # redondeamos\n","print(f'\\nNuestro sistema produjo el resultado correcto en el {score}% de los casos.\\n')\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
